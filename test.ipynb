{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "import aesara\n",
    "import aesara.sparse\n",
    "import aesara.tensor as aet\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "\n",
    "from tabmat import CategoricalMatrix as TabMat\n",
    "\n",
    "import example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, this only works for the particular case where the design matrix is of the type\n",
    "\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "1 & 0 & \\cdots & 0 \\\\\n",
    "1 & 0 & \\cdots & 0 \\\\\n",
    "0 & 1 & \\cdots & 0 \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
    "0 & 0 & \\cdots & 1\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "i.e. one, and only one, 1 per row.\n",
    "\n",
    "The idea is to extend it to the general case where you can have zero, one, or more than one 1s. \n",
    "\n",
    "1. Zero: When the observation has the reference level for all the categoricals in the linear term. It's not that the row is 0 for the whole design matrix. Here I'm not considering the Intercept term.\n",
    "2. One: When there's only one categorical predictor and the observation does not have the reference level or when there's more than one categorical predictors but the observation has the reference level in all but one of them.\n",
    "3. More than one: When there's more than one categorical predictor and the observation does not have the reference level in at least two of them.\n",
    "\n",
    "\n",
    "\n",
    "**Update**\n",
    "\n",
    "The new implementation works for the most general case :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.20427091, -1.63900486, -0.42584969, -0.74500956,  1.25061673,\n",
       "       -3.16130481,  2.77291668,  1.25061673,  2.77291668, -0.48267259])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import formulae\n",
    "\n",
    "rng = np.random.default_rng(1234)\n",
    "\n",
    "x = rng.choice([\"A\", \"B\", \"C\"], size=10)\n",
    "y = rng.choice([\"X\", \"Y\", \"Z\"], size=10)\n",
    "z = rng.choice([\"M\", \"N\", \"O\"], size=10)\n",
    "df = pd.DataFrame({\"x\": x, \"y\": y, \"z\": z})\n",
    "\n",
    "X = formulae.design_matrices(\"0 + x + y + z\", df).common.design_matrix\n",
    "\n",
    "X_indices = np.ascontiguousarray(np.vstack(np.where(X != 0)).T).astype(np.int32)\n",
    "vector = rng.normal(size=X.shape[1])\n",
    "result = np.zeros(X.shape[0], dtype=float)\n",
    "\n",
    "example.mat_vec_1d_dummy(X_indices, vector, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(np.dot(X, vector), result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The \"categorical variables\"\n",
    "strings = list(string.ascii_lowercase) + list(string.ascii_uppercase)\n",
    "strings += [s * 2 for s in strings]\n",
    "len(strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CategoricalMatrix:\n",
    "    def __init__(self, x):\n",
    "        self.indices = pd.Categorical(x).codes.astype(np.int32)\n",
    "        self.length = self.indices.shape[0]\n",
    "    \n",
    "    def dot(self, other):\n",
    "        # For now, let's assume 'other' is a column vector.\n",
    "        out = np.zeros(self.length, dtype=other.dtype)\n",
    "        example.mat_vec_1d(self.indices, other, out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CategoricalMatrix2:\n",
    "    def __init__(self, X):\n",
    "        self.length = X.shape[0]\n",
    "        self.X_indices = np.ascontiguousarray(np.vstack(np.where(X != 0)).T).astype(np.int32)\n",
    "        \n",
    "    def dot(self, other):\n",
    "        result = np.zeros(self.length, dtype=other.dtype)\n",
    "        example.mat_vec_1d_dummy(self.X_indices, other, result)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.choice(strings, size=1000)\n",
    "matrix_dense = np.asarray(pd.get_dummies(x))\n",
    "matrix_sparse = sp.csr_matrix(matrix_dense)\n",
    "categorical = CategoricalMatrix(x)\n",
    "categorical_2 = CategoricalMatrix2(matrix_dense)\n",
    "sp_matrix = sp.csr_matrix(matrix_dense)\n",
    "tbmat = TabMat(x)\n",
    "y = np.arange(len(strings), dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(categorical_2.dot(y) == categorical.dot(y)).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining Aesara functions..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "aet_x = aet.dmatrix(\"x\")\n",
    "aet_y = aet.dvector(\"y\")\n",
    "aet_Y = aet.dmatrix(\"y\")\n",
    "\n",
    "x_sparse = aesara.sparse.CSR(sp_matrix.data, sp_matrix.indices, sp_matrix.indptr, sp_matrix.shape)\n",
    "\n",
    "aet_dot = aesara.function([aet_x, aet_y], aet.dot(aet_x, aet_y))\n",
    "aet_sparse_dot = aesara.function([x_sparse, aet_Y], aesara.sparse.structured_dot(x_sparse, aet_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 µs ± 47.8 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      "2.33 µs ± 42.5 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      "70 µs ± 2.96 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "6.16 µs ± 54.4 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      "8.26 µs ± 676 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      "100 µs ± 1.27 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "34.8 µs ± 67.6 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit categorical.dot(y)\n",
    "%timeit categorical_2.dot(y)\n",
    "%timeit matrix_dense.dot(y)\n",
    "%timeit sp_matrix.dot(y)\n",
    "%timeit tbmat.matvec(y)\n",
    "%timeit aet_dot(matrix_dense, y)\n",
    "%timeit aet_sparse_dot(sp_matrix, y[:, None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68.2 µs ± 663 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "101 µs ± 175 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "20.4 ms ± 595 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "186 µs ± 1.09 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "58.1 µs ± 4.35 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "22.5 ms ± 376 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "255 µs ± 14 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "x = np.random.choice(strings, size=100000)\n",
    "matrix_dense = np.asarray(pd.get_dummies(x))\n",
    "matrix_sparse = sp.csr_matrix(matrix_dense)\n",
    "\n",
    "categorical = CategoricalMatrix(x)\n",
    "categorical_2 = CategoricalMatrix2(matrix_dense)\n",
    "sp_matrix = sp.csr_matrix(matrix_dense)\n",
    "tbmat = TabMat(x)\n",
    "\n",
    "%timeit categorical.dot(y)\n",
    "%timeit categorical_2.dot(y)\n",
    "%timeit matrix_dense.dot(y)\n",
    "%timeit sp_matrix.dot(y)\n",
    "%timeit tbmat.matvec(y)\n",
    "%timeit aet_dot(matrix_dense, y)\n",
    "%timeit aet_sparse_dot(sp_matrix, y[:, None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.choice(strings, size=10000000)\n",
    "matrix_dense = np.asarray(pd.get_dummies(x))\n",
    "matrix_sparse = sp.csr_matrix(matrix_dense)\n",
    "\n",
    "categorical = CategoricalMatrix(x)\n",
    "categorical_2 = CategoricalMatrix2(matrix_dense)\n",
    "sp_matrix = sp.csr_matrix(matrix_dense)\n",
    "tbmat = TabMat(x)\n",
    "\n",
    "%timeit categorical.dot(y)\n",
    "%timeit categorical_2.dot(y)\n",
    "%timeit matrix_dense.dot(y)\n",
    "%timeit sp_matrix.dot(y)\n",
    "%timeit tbmat.matvec(y)\n",
    "%timeit aet_dot(matrix_dense, y)\n",
    "%timeit aet_sparse_dot(sp_matrix, y[:, None])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3fb55a5ee3f39f92efc764f94bee8d23b2d6c27a57dd0a3970937cfa1b6f6994"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('bmb': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
