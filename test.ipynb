{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "import aesara\n",
    "import aesara.sparse\n",
    "import aesara.tensor as aet\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "\n",
    "from tabmat import CategoricalMatrix as TabMat\n",
    "\n",
    "import example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, this only works for the particular case where the design matrix is of the type\n",
    "\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "1 & 0 & \\cdots & 0 \\\\\n",
    "1 & 0 & \\cdots & 0 \\\\\n",
    "0 & 1 & \\cdots & 0 \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
    "0 & 0 & \\cdots & 1\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "i.e. one, and only one, 1 per row.\n",
    "\n",
    "The idea is to extend it to the general case where you can have zero, one, or more than one 1s. \n",
    "\n",
    "1. Zero: When the observation has the reference level for all the categoricals in the linear term. It's not that the row is 0 for the whole design matrix. Here I'm not considering the Intercept term.\n",
    "2. One: When there's only one categorical predictor and the observation does not have the reference level or when there's more than one categorical predictors but the observation has the reference level in all but one of them.\n",
    "3. More than one: When there's more than one categorical predictor and the observation does not have the reference level in at least two of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The \"categorical variables\"\n",
    "strings = list(string.ascii_lowercase) + list(string.ascii_uppercase)\n",
    "strings += [s * 2 for s in strings]\n",
    "len(strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CategoricalMatrix:\n",
    "    def __init__(self, x):\n",
    "        self.indices = pd.Categorical(x).codes.astype(np.int32)\n",
    "        self.length = self.indices.shape[0]\n",
    "    \n",
    "    def dot(self, other):\n",
    "        # For now, let's assume 'other' is a column vector.\n",
    "        out = np.zeros(self.length, dtype=other.dtype)\n",
    "        example.mat_vec_1d(self.indices, other, out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.choice(strings, size=1000)\n",
    "matrix_dense = np.asarray(pd.get_dummies(x))\n",
    "matrix_sparse = sp.csr_matrix(matrix_dense)\n",
    "\n",
    "categorical = CategoricalMatrix(x)\n",
    "sp_matrix = sp.csr_matrix(matrix_dense)\n",
    "tbmat = TabMat(x)\n",
    "y = np.arange(len(strings), dtype=np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining Aesara functions..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "aet_x = aet.dmatrix(\"x\")\n",
    "aet_y = aet.dvector(\"y\")\n",
    "aet_Y = aet.dmatrix(\"y\")\n",
    "\n",
    "x_sparse = aesara.sparse.CSR(sp_matrix.data, sp_matrix.indices, sp_matrix.indptr, sp_matrix.shape)\n",
    "\n",
    "aet_dot = aesara.function([aet_x, aet_y], aet.dot(aet_x, aet_y))\n",
    "aet_sparse_dot = aesara.function([x_sparse, aet_Y], aesara.sparse.structured_dot(x_sparse, aet_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.07 µs ± 165 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      "130 µs ± 19.8 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "6.54 µs ± 256 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      "20.8 µs ± 5.06 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "112 µs ± 4.52 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "36.6 µs ± 582 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit categorical.dot(y)\n",
    "%timeit matrix_dense.dot(y)\n",
    "%timeit sp_matrix.dot(y)\n",
    "%timeit tbmat.matvec(y)\n",
    "%timeit aet_dot(matrix_dense, y)\n",
    "%timeit aet_sparse_dot(sp_matrix, y[:, None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72.9 µs ± 1.24 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "25 ms ± 1.56 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "206 µs ± 6.22 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "103 µs ± 22.1 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "24 ms ± 657 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "314 µs ± 8.88 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "x = np.random.choice(strings, size=100000)\n",
    "matrix_dense = np.asarray(pd.get_dummies(x))\n",
    "matrix_sparse = sp.csr_matrix(matrix_dense)\n",
    "\n",
    "categorical = CategoricalMatrix(x)\n",
    "sp_matrix = sp.csr_matrix(matrix_dense)\n",
    "tbmat = TabMat(x)\n",
    "\n",
    "%timeit categorical.dot(y)\n",
    "%timeit matrix_dense.dot(y)\n",
    "%timeit sp_matrix.dot(y)\n",
    "%timeit tbmat.matvec(y)\n",
    "%timeit aet_dot(matrix_dense, y)\n",
    "%timeit aet_sparse_dot(sp_matrix, y[:, None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 ms ± 226 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "2.04 s ± 17.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "61.8 ms ± 521 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "37.1 ms ± 2.89 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "2.98 s ± 44.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "63.2 ms ± 669 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "x = np.random.choice(strings, size=10000000)\n",
    "matrix_dense = np.asarray(pd.get_dummies(x))\n",
    "matrix_sparse = sp.csr_matrix(matrix_dense)\n",
    "\n",
    "categorical = CategoricalMatrix(x)\n",
    "sp_matrix = sp.csr_matrix(matrix_dense)\n",
    "tbmat = TabMat(x)\n",
    "\n",
    "%timeit categorical.dot(y)\n",
    "%timeit matrix_dense.dot(y)\n",
    "%timeit sp_matrix.dot(y)\n",
    "%timeit tbmat.matvec(y)\n",
    "%timeit aet_dot(matrix_dense, y)\n",
    "%timeit aet_sparse_dot(sp_matrix, y[:, None])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3fb55a5ee3f39f92efc764f94bee8d23b2d6c27a57dd0a3970937cfa1b6f6994"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('bmb': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
